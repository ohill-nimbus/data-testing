{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a10c890e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from src.auth.aurora import get_portal_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98d76df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "portal_client = get_portal_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09b91fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "site_id = 8928"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3779b721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional assets on tests: 11377682, 11377748\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tests_df = portal_client.query_to_pandas(\n",
    "    \"\"\"SELECT\n",
    "        test.id,\n",
    "        test.created_at,\n",
    "        site.template_id,\n",
    "        site.protocol_id,\n",
    "        mode_change.toc_id,\n",
    "        test.panel,\n",
    "        test.domain,\n",
    "        test.loop,\n",
    "        test.address,\n",
    "        test.sub_address\n",
    "    FROM topaz.api_service_tests AS test\n",
    "    INNER JOIN topaz.api_mode_changes AS mode_change\n",
    "    ON test.mode_change_id = mode_change.id\n",
    "    INNER JOIN topaz.api_sites AS site\n",
    "    ON test.site_id = site.id\n",
    "    WHERE test.site_id = %(site_id)s\n",
    "    AND test.created_at >= '2024-01-01 00:00:00'\"\"\",\n",
    "    {\"site_id\": site_id}\n",
    ")\n",
    "missing_task_records = False\n",
    "changed_asset_type_records = []\n",
    "tests_df['panel'] = tests_df['panel'].fillna(-999)\n",
    "tests_df['domain'] = tests_df['domain'].fillna(-999)\n",
    "tests_df['loop'] = tests_df['loop'].fillna(-999)\n",
    "tests_df['address'] = tests_df['address'].fillna(-999)\n",
    "tests_df['sub_address'] = tests_df['sub_address'].fillna(-999)\n",
    "tests_df.loc[tests_df['sub_address'] == '', 'sub_address'] = -999\n",
    "tests_df.loc[tests_df['sub_address'] == 0, 'sub_address'] = -999\n",
    "\n",
    "for (template_id, protocol_id, toc_id), test_df in tests_df.groupby([\"template_id\", \"protocol_id\", \"toc_id\"]):\n",
    "    template_df = portal_client.query_to_pandas(\n",
    "        \"\"\"SELECT\n",
    "            id AS task_id,\n",
    "            asset_type,\n",
    "            created_at,\n",
    "            deleted_at\n",
    "        FROM topaz.api_service_tasks\n",
    "        WHERE template_id = %(template_id)s\n",
    "        AND `type` IN (1,3)\"\"\",\n",
    "        {\"template_id\": int(template_id)}\n",
    "    )\n",
    "    template_df[\"asset_type\"] = template_df[\"asset_type\"].str.lower()\n",
    "    toc_df = portal_client.query_to_pandas(\n",
    "        \"\"\"SELECT `panel`, `domain`, `loop`, `address`, `sub_address`, `type`, `lcs_device_type`, `created_at` AS toc_created_at, `deleted_at` AS toc_deleted_at\n",
    "        FROM topaz.api_toc_rows\n",
    "        WHERE toc_id = %(toc_id)s\"\"\",\n",
    "        {\"toc_id\": int(toc_id)}\n",
    "    )\n",
    "    toc_df[\"type\"] = toc_df[\"type\"].str.lower()\n",
    "    toc_df[\"lcs_device_type\"] = toc_df[\"lcs_device_type\"].str.lower()\n",
    "    toc_df['panel'] = toc_df['panel'].fillna(-999)\n",
    "    toc_df['domain'] = toc_df['domain'].fillna(-999)\n",
    "    toc_df['loop'] = toc_df['loop'].fillna(-999)\n",
    "    toc_df['address'] = toc_df['address'].fillna(-999)\n",
    "    toc_df['sub_address'] = toc_df['sub_address'].fillna(-999)\n",
    "    toc_df.loc[toc_df['sub_address'] == 0, 'sub_address'] = -999\n",
    "    toc_df[\"legacy_device_type\"] = toc_df[\"lcs_device_type\"].copy()\n",
    "    other_mask = toc_df[\"lcs_device_type\"] == \"other\"\n",
    "    toc_df.loc[other_mask, \"lcs_device_type\"] = toc_df.loc[other_mask, \"type\"]\n",
    "    merged_df = pd.merge(\n",
    "        how=\"inner\",\n",
    "        left=test_df,\n",
    "        left_on=[\"panel\", \"domain\", \"loop\", \"address\", \"sub_address\"],\n",
    "        right=toc_df,\n",
    "        right_on=[\"panel\", \"domain\", \"loop\", \"address\", \"sub_address\"],\n",
    "    )\n",
    "    time_mask = (merged_df[\"created_at\"] >= merged_df[\"toc_created_at\"]) & (\n",
    "        (\n",
    "            merged_df[\"created_at\"] < merged_df[\"toc_deleted_at\"]\n",
    "        ) | merged_df[\"toc_deleted_at\"].isnull()\n",
    "    )\n",
    "    merged_df = merged_df[time_mask]\n",
    "\n",
    "    template_df[\"key\"] = 1\n",
    "    blank_asset_mask = template_df[\"asset_type\"] == \"\"\n",
    "    all_assets = pd.DataFrame(\n",
    "        {\"asset_type\": toc_df[\"lcs_device_type\"].unique()}\n",
    "    )\n",
    "    all_assets[\"key\"] = 1\n",
    "    full_template_df = pd.concat([\n",
    "        pd.merge(\n",
    "            left=template_df.loc[blank_asset_mask, [\"key\", \"task_id\", \"created_at\", \"deleted_at\"]],\n",
    "            right=all_assets.loc[:, [\"key\", \"asset_type\"]],\n",
    "            on=\"key\"\n",
    "        ),\n",
    "        template_df.loc[~blank_asset_mask, [\"key\", \"task_id\", \"created_at\", \"deleted_at\", \"asset_type\"]]\n",
    "    ])\n",
    "    normal_merged_df = pd.merge(\n",
    "        how=\"inner\",\n",
    "        left=merged_df,\n",
    "        left_on=\"lcs_device_type\",\n",
    "        right=full_template_df,\n",
    "        right_on=\"asset_type\",\n",
    "    )\n",
    "\n",
    "    if protocol_id == 34:\n",
    "        merged_df[\"el_key\"] = 1\n",
    "    else:\n",
    "        merged_df[\"el_key\"] = 0\n",
    "    template_df[\"el_key\"] = 1 * (template_df[\"asset_type\"] == \"el\")\n",
    "\n",
    "    el_merged_df = pd.merge(\n",
    "        how=\"inner\",\n",
    "        left=merged_df[merged_df[\"el_key\"] == 1],\n",
    "        left_on=\"el_key\",\n",
    "        right=template_df[template_df[\"el_key\"] == 1],\n",
    "        right_on=\"el_key\",\n",
    "    )\n",
    "\n",
    "    if protocol_id == 35:\n",
    "        merged_df[\"ext_key\"] = 1 * (\n",
    "            (merged_df[\"legacy_device_type\"] != \"other\")\n",
    "        )\n",
    "    else:\n",
    "        merged_df[\"ext_key\"] = 0\n",
    "    template_df[\"ext_key\"] = 1 * (template_df[\"asset_type\"] == \"ext\")\n",
    "\n",
    "    ext_merged_df = pd.merge(\n",
    "        how=\"inner\",\n",
    "        left=merged_df[merged_df[\"ext_key\"] == 1],\n",
    "        left_on=\"ext_key\",\n",
    "        right=template_df[template_df[\"ext_key\"] == 1],\n",
    "        right_on=\"ext_key\",\n",
    "    )\n",
    "\n",
    "    merged_df = pd.concat([\n",
    "        normal_merged_df,\n",
    "        el_merged_df,\n",
    "        ext_merged_df\n",
    "    ])\n",
    "\n",
    "    timing_mask = (merged_df[\"created_at_x\"] >= merged_df[\"created_at_y\"]) & (\n",
    "        (merged_df[\"created_at_x\"] < merged_df[\"deleted_at\"]) | (\n",
    "            merged_df[\"deleted_at\"].isnull()\n",
    "        )\n",
    "    )\n",
    "    merged_df = merged_df[timing_mask]\n",
    "    if merged_df.empty:\n",
    "        print(\"----> No tasks\")\n",
    "        continue\n",
    "    for (test_id,), tasks_df in merged_df.groupby([\"id\"]):\n",
    "        task_record_df = portal_client.query_to_pandas(\n",
    "            \"\"\"SELECT tr.test_id, tr.task_id, t.asset_type\n",
    "            FROM topaz.api_service_tasks_record AS tr\n",
    "            LEFT JOIN topaz.api_service_tasks AS t\n",
    "            ON tr.task_id = t.id\n",
    "            WHERE test_id = %(test_id)s\"\"\",\n",
    "            {\"test_id\": int(test_id)}\n",
    "        )\n",
    "        additional_assets = set(task_record_df[\"asset_type\"]) - set(tasks_df[\"asset_type\"]) - {''}\n",
    "        if len(additional_assets) > 0:\n",
    "            changed_asset_type_records.append(test_id)\n",
    "        joined_tasks = pd.merge(\n",
    "            how=\"left\",\n",
    "            left=tasks_df,\n",
    "            left_on=[\"id\", \"task_id\"],\n",
    "            right=task_record_df,\n",
    "            right_on=[\"test_id\", \"task_id\"]\n",
    "        )\n",
    "        missing_tasks = joined_tasks[joined_tasks[\"asset_type_y\"].isnull()]\n",
    "        if not missing_tasks.empty:\n",
    "            missing_task_records = True\n",
    "            break\n",
    "    if missing_task_records:\n",
    "        break\n",
    "assert not (missing_task_records)\n",
    "if missing_task_records:\n",
    "    missing_tasks_string = \", \".join(str(int(task)) for task in missing_tasks[\"task_id\"].values)\n",
    "    print(f\"{test_id} missing tasks {missing_tasks_string}\")\n",
    "if (len(changed_asset_type_records) > 0):\n",
    "    additional_assets_string = \", \".join(str(int(test)) for test in changed_asset_type_records)\n",
    "    print(f\"Additional assets on tests: {additional_assets_string}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-testing-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
